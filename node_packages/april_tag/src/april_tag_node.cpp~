//
// adapted from ros example and april tag examples - palash
//
#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include "AprilTags/TagDetector.h"
#include "AprilTags/Tag36h11.h"

#include "april_tag/AprilTag.h" // rosmsg
#include "april_tag/AprilTagList.h" // rosmsg

#include <sys/time.h>
#include <std_msgs/Float64.h>

// for publishing the pose
#include <geometry_msgs/PoseStamped.h>
#include <visualization_msgs/Marker.h>

static const std::string OPENCV_WINDOW = "Image window"; //for viewing video

const double PI = 3.14159265358979323846;
const double TWOPI = 2.0*PI;

/**
 * Normalize angle to be within the interval [-pi,pi].
 */
inline double standardRad(double t) {
  if (t >= 0.) {
    t = fmod(t+PI, TWOPI) - PI;
  } else {
    t = fmod(t-PI, -TWOPI) + PI;
  }
  return t;
}

/**
 * Convert rotation matrix to Euler angles
 */
void wRo_to_euler(const Eigen::Matrix3d& wRo, double& yaw, double& pitch, double& roll) {
    yaw = standardRad(atan2(wRo(1,0), wRo(0,0)));
    double c = cos(yaw);
    double s = sin(yaw);
    pitch = standardRad(atan2(-wRo(2,0), wRo(0,0)*c + wRo(1,0)*s));
    roll  = standardRad(atan2(wRo(0,2)*s - wRo(1,2)*c, -wRo(0,1)*s + wRo(1,1)*c));
}


// utility function to provide current system time (used below in
// determining frame rate at which images are being Ied)
double tic() {
  struct timeval t;
  gettimeofday(&t, NULL);
  return ((double)t.tv_sec + ((double)t.tv_usec)/1000000.);
}

class AprilTagNode
{
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  image_transport::Subscriber image_sub_;
  image_transport::Publisher image_pub_;
  ros::Publisher tag_list_pub;
  ros::Publisher move_dist_x;
  ros::Publisher move_dist_y;
  ros::Publisher move_dist_z;
  ros::Publisher tag_pose;
  ros::Publisher marker_pub;
  AprilTags::TagDetector* tag_detector;
  int frame;
  std_msgs::Float64 x_dist;
  std_msgs::Float64 y_dist;
  std_msgs::Float64 z_dist;
  geometry_msgs::PoseStamped pose_stamped;

  // allow configurations for these:  
  AprilTags::TagCodes tag_codes;
  double camera_focal_length_x; // in pixels. late 2013 macbookpro retina = 700
  double camera_focal_length_y; // in pixels
  double tag_size; // tag side length of frame in meters 
  bool  show_debug_image;
  double m_px; // camera principal point
  double m_py;
  int m_deviceId;


public:
  AprilTagNode() : 
    it_(nh_), 
    tag_codes(AprilTags::tagCodes36h11), 
    tag_detector(NULL),
    camera_focal_length_x(140.660189),
    camera_focal_length_y(134.910994), 
    tag_size(0.165), // 1 1/8in marker = 0.029m
    show_debug_image(false),
    m_px(80),
    m_py(60),
    m_deviceId(0),
    frame(0)
  {
    // Subscrive to input video feed and publish output video feed
     
    image_sub_ = it_.subscribe("/usb_cam/image_raw", 1, &AprilTagNode::imageCb, this);
    image_pub_ = it_.advertise("/april_tag_debug/output_video", 1);

    // for tag pose
    tag_pose = nh_.advertise<geometry_msgs::PoseStamped>("tag_pose", 100);
    marker_pub = nh_.advertise<visualization_msgs::Marker>("visualization_marker", 100);

    tag_list_pub = nh_.advertise<april_tag::AprilTagList>("/april_tags", 100);
    move_dist_x = nh_.advertise<std_msgs::Float64>("/move_Xdist", 100);
    move_dist_y = nh_.advertise<std_msgs::Float64>("/move_Ydist", 100);
    move_dist_z = nh_.advertise<std_msgs::Float64>("/move_Zdist", 100);
    cout << "got focal length x " << camera_focal_length_x << endl;
    cout << "got focal length  y " << camera_focal_length_y << endl;
    cout << "got tag size " << tag_size << endl;
    tag_detector = new AprilTags::TagDetector(tag_codes);
   
    if (show_debug_image) {
      cv::namedWindow(OPENCV_WINDOW);
    }

  }

  ~AprilTagNode()
  {
    if (show_debug_image) {
     cv::destroyWindow(OPENCV_WINDOW);
    }
  }

   
  //  time_t(&begin);
    

   april_tag::AprilTag convert_to_msg(AprilTags::TagDetection& detection, int width, int height) {
   
   //cout << "time taken first " << t0<< endl;
    // recovering the relative pose of a tag:

    // NOTE: for this to be accurate, it is necessary to use the
    // actual camera parameters here as well as the actual tag size
    // (m_fx, m_fy, m_px, m_py, m_tagSize)

    Eigen::Vector3d translation;
    Eigen::Matrix3d rotation;
    //ROS_INFO("cx %d cy %d ", camera_focal_length_x, camera_focal_length_y);	
    detection.getRelativeTranslationRotation(tag_size, 
                                             camera_focal_length_x, 
                                             camera_focal_length_y, 
                                             m_px,		  //  width / 2, 
                                             m_py,		// height / 2,
                                             translation, 
                                             rotation);

    Eigen::Matrix3d F;
    F <<
      1, 0,  0,
      0,  -1,  0,
      0,  0,  1;
    Eigen::Matrix3d fixed_rot = F*rotation;
    double yaw, pitch, roll;
    wRo_to_euler(fixed_rot, yaw, pitch, roll);
    yaw=(yaw*180)/PI;
    pitch=(pitch*180)/PI;
    roll=(roll*180)/PI;
    // Three lines for tag pose
     Eigen::Matrix4d transform = detection.getRelativeTransform(tag_size, camera_focal_length_x, camera_focal_length_y, m_px, m_py);
  	 Eigen::Matrix3d rot = transform.block(0,0,3,3);
 	 Eigen::Quaternion<double> rot_quaternion = Eigen::Quaternion<double>(rot);
 	 // tag pose lines end here

    april_tag::AprilTag tag_msg;

    tag_msg.id = detection.id;
    tag_msg.hamming_distance = detection.hammingDistance;
    tag_msg.distance = translation.norm() * 100.0;
    tag_msg.z = translation(0) * 100.0; // depth from camera
    tag_msg.x = translation(1) * 100.0; // horizontal displacement (camera pov right = +ve)
    tag_msg.y = translation(2) * 100.0; // vertical displacement
    tag_msg.yaw = yaw;
    tag_msg.pitch = pitch;
    tag_msg.roll = roll;
    z_dist.data = - translation(0) * 100.0;
    x_dist.data = - translation(1) * 100.0; // horizontal displacement (camera pov right = +ve)
    y_dist.data = - translation(2) * 100.0; // vertical displacement

      pose_stamped.header.frame_id = 1;
      pose_stamped.header.stamp = ros::Time::now();
      /*
      pose_stamped.pose.orientation.x = rot_quaternion.x();
      pose_stamped.pose.orientation.y = rot_quaternion.y();
      pose_stamped.pose.orientation.z = rot_quaternion.z();
      pose_stamped.pose.orientation.w = rot_quaternion.w();

      pose_stamped.pose.position.x = translation(1) * 100.0;
      pose_stamped.pose.position.y = translation(2) * 100.0;
      pose_stamped.pose.position.z = translation(0) * 100.0;
      */

      pose_stamped.pose.orientation.x = 0;
      pose_stamped.pose.orientation.y = 0;
      pose_stamped.pose.orientation.z = 0;
      pose_stamped.pose.orientation.w = 0;

      pose_stamped.pose.position.x = 0;
      pose_stamped.pose.position.y = 0;
      pose_stamped.pose.position.z = 0;


    return tag_msg;

  }
   
  void processCvImage(cv_bridge::CvImagePtr cv_ptr) 
  {
    cv::Mat image_gray;
    cv::cvtColor(cv_ptr->image, image_gray, CV_BGR2GRAY);
     double t0= tic();
    vector<AprilTags::TagDetection> detections = tag_detector->extractTags(image_gray);
    vector<april_tag::AprilTag> tag_msgs;
    //vector<april_tag::AprilTag> err_dist;
       double dt = tic()-t0;
  //cout << "time taken " << dt << endl;


    for (int i=0; i<detections.size(); i++) {
      detections[i].draw(cv_ptr->image);
      tag_msgs.push_back(convert_to_msg(detections[i], cv_ptr->image.cols, cv_ptr->image.rows));
      //err_dist.push_back(convert_to_msg1(detections[i], cv_ptr->image.cols, cv_ptr->image.rows));    
    }
    tag_pose.publish(pose_stamped);
    if(detections.size() > 0) { // take this out if you want absence notificaiton
      april_tag::AprilTagList tag_list;
      april_tag::AprilTagList dist_list;
      tag_list.april_tags = tag_msgs;
      //dist_list.april_tags= err_dist;
      tag_list_pub.publish(tag_list);
      move_dist_x.publish(x_dist);
      move_dist_y.publish(y_dist);
      move_dist_z.publish(z_dist);
      tag_pose.publish(pose_stamped);
      //move_dist.publish(dist_list);
    }
  }


  void imageCb(const sensor_msgs::ImageConstPtr& msg)
  {
   

    
    double last_t = tic();
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
      cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
    }
    catch (cv_bridge::Exception& e)
    {
      ROS_ERROR("cv_bridge exception: %s", e.what());
      return;
    }

    processCvImage(cv_ptr);

    if (show_debug_image) {
      // Update GUI Window
      cv::imshow(OPENCV_WINDOW, cv_ptr->image);
      cv::waitKey(3);
    }

    // Output modified video stream
    image_pub_.publish(cv_ptr->toImageMsg());
     frame++;
     //cout << frame << " fps" << endl;
      if (frame % 10 == 0) {
        double t = tic();
        cout << " update rate " << 1./(t-last_t) << " Hz" << endl;
        //cout << "  " << (t-last_t) << " fps" << endl;
        last_t = t;
      }
  }
};

int main(int argc, char** argv)
{
  
  ros::init(argc, argv, "april_tag_node");
  AprilTagNode atn;
 
  ros::spin();
  return 0;
}
